{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 10 different csv files for each year, which makes analysis of this data difficult. Therefore, I decided to combine all of them and make a single dataset containing US countys' average weekly temperature from 2013 till 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV files to read\n",
    "csv_files = sorted(glob.glob('weeklyTemp\\*.csv'))  # Adjust the path to your CSV files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the dataframes\n",
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each file and process it\n",
    "for file in csv_files:\n",
    "    # Extract the year from the filename (assuming the year is in the filename)\n",
    "    year = file.split('_')[-1].split('.')[0]\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Pivot the dataframe\n",
    "    df_pivot = df.pivot_table(index=['county_name', 'state_id'], \n",
    "                              columns='week', \n",
    "                              values='mean_temperature', \n",
    "                              aggfunc='mean')\n",
    "    \n",
    "    # Flatten the columns\n",
    "    df_pivot.columns = [f\"Week {int(week)} ({year})\" for week in df_pivot.columns]\n",
    "    \n",
    "    # Reset index to get county_name and state_id as columns\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "    \n",
    "    # Append to the list of dataframes\n",
    "    dfs.append(df_pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weeklyTemp\\\\US_County_Weekly_Temperature_2013.csv', 'weeklyTemp\\\\US_County_Weekly_Temperature_2014.csv', 'weeklyTemp\\\\US_County_Weekly_Temperature_2015.csv', 'weeklyTemp\\\\US_County_Weekly_Temperature_2016.csv', 'weeklyTemp\\\\US_County_Weekly_Temperature_2017.csv', 'weeklyTemp\\\\US_County_Weekly_Temperature_2018.csv', 'weeklyTemp\\\\US_County_Weekly_Temperature_2019.csv', 'weeklyTemp\\\\US_County_Weekly_Temperature_2020.csv', 'weeklyTemp\\\\US_County_Weekly_Temperature_2021.csv', 'weeklyTemp\\\\US_County_Weekly_Temperature_2022.csv', 'weeklyTemp\\\\US_County_Weekly_Temperature_2023.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(csv_files)  # This should print a list of all the CSV files found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: weeklyTemp\\US_County_Weekly_Temperature_2013.csv\n",
      "Processing file: weeklyTemp\\US_County_Weekly_Temperature_2014.csv\n",
      "Processing file: weeklyTemp\\US_County_Weekly_Temperature_2015.csv\n",
      "Processing file: weeklyTemp\\US_County_Weekly_Temperature_2016.csv\n",
      "Processing file: weeklyTemp\\US_County_Weekly_Temperature_2017.csv\n",
      "Processing file: weeklyTemp\\US_County_Weekly_Temperature_2018.csv\n",
      "Processing file: weeklyTemp\\US_County_Weekly_Temperature_2019.csv\n",
      "Processing file: weeklyTemp\\US_County_Weekly_Temperature_2020.csv\n",
      "Processing file: weeklyTemp\\US_County_Weekly_Temperature_2021.csv\n",
      "Processing file: weeklyTemp\\US_County_Weekly_Temperature_2022.csv\n",
      "Processing file: weeklyTemp\\US_County_Weekly_Temperature_2023.csv\n"
     ]
    }
   ],
   "source": [
    "for file in csv_files:\n",
    "    print(f\"Processing file: {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all dataframes on county_name and state_id\n",
    "final_df = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    final_df = pd.merge(final_df, df, on=['county_name', 'state_id'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has been successfully consolidated and saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "final_df.to_csv('final_temperature_data.csv', index=False)\n",
    "\n",
    "print(\"The data has been successfully consolidated and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have combined all 10 csv file containing weekly temperature of US counties in one single CSV file and we can start analyzing it.\n",
    "Also in order to make visualizations, we need geojson file containing US counties as well. I have found and downloaded that file, and now let's try to combine it with the csv file we have prepared so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m geojson_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounties.geojson\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(geojson_path) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 8\u001b[0m     geojson_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Extract properties (non-geometry data) from the GeoJSON file\u001b[39;00m\n\u001b[0;32m     11\u001b[0m counties_properties \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(geojson_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "csv_path = 'final_temperature_data.csv'\n",
    "temperature_data = pd.read_csv(csv_path)\n",
    "\n",
    "# Load the GeoJSON file\n",
    "geojson_path = 'counties.geojson'\n",
    "with open(geojson_path) as f:\n",
    "    geojson_data = json.load(f)\n",
    "\n",
    "# Extract properties (non-geometry data) from the GeoJSON file\n",
    "counties_properties = pd.json_normalize(geojson_data['features'])\n",
    "\n",
    "# Merge the datasets on the county name columns\n",
    "merged_data = pd.merge(temperature_data, counties_properties, left_on='county_name', right_on='properties.NAME', how='left')\n",
    "\n",
    "# Save the merged data to a new CSV file\n",
    "output_path = 'path_to_your/merged_temperature_data.csv'\n",
    "merged_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Merged data saved to:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatialEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
